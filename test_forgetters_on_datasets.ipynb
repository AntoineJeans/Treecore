{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#sklearn models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "# Forgetters\n",
    "from Forgetters.GradientBoostingForgetters import GBClassifierForgetter, GBRegressorForgetter\n",
    "from Forgetters.AdaptiveBoostingForgetters import ABClassifierForgetter, ABRegressorForgetter\n",
    "\n",
    "# Compression strategies\n",
    "from CompressionStrategies.DropUnforgettable import DropUnforgettableClassification\n",
    "from CompressionStrategies.DropNForgets import DropNForgetsClassification\n",
    "\n",
    "# sklearn stuff\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Other utils\n",
    "from utils import predictions_to_y, get_accuracy_score\n",
    "from DatasetLoader import DatasetLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_strategy = DropNForgetsClassification(n=1)\n",
    "base_model = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "def plot_compressed_length_by_n_estimators(X, y, lr=1, step=10, max=500):\n",
    "    kept_ratio = []\n",
    "    \n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    \n",
    "    x = range(1,max,step)\n",
    "    \n",
    "    for n in x:\n",
    "        forg = ABClassifierForgetter(estimator=base_model, learning_rate=lr, n_estimators=n)\n",
    "        forg.fit(X, y)\n",
    "        _, y_compressed = forg.transform(X, compression_strategy, y=y)\n",
    "        print(len(y))\n",
    "        print(len(y_compressed))\n",
    "        kept_ratio.append(len(y_compressed) / len(y))\n",
    "        \n",
    "    \n",
    "\n",
    "    plt.plot(x, kept_ratio, label=\"ABClassifierForgetter\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"Ratio de points conservés\")\n",
    "    plt.title(\"Ratio de points conservés selon n_estimators\")\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "\n",
    "def plot_dataset_convergence(X, y):\n",
    "    plot_compressed_length_by_n_estimators(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "625\n",
      "625\n",
      "0\n",
      "625\n",
      "47330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ABClassifierForgetter was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ABClassifierForgetter was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ABClassifierForgetter was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "63580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ABClassifierForgetter was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "71435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ABClassifierForgetter was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "72789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ABClassifierForgetter was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m y \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(y)\n\u001b[0;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mplot_dataset_convergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 31\u001b[0m, in \u001b[0;36mplot_dataset_convergence\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_dataset_convergence\u001b[39m(X, y):\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mplot_compressed_length_by_n_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 15\u001b[0m, in \u001b[0;36mplot_compressed_length_by_n_estimators\u001b[1;34m(X, y, lr, step, max)\u001b[0m\n\u001b[0;32m     13\u001b[0m forg \u001b[38;5;241m=\u001b[39m ABClassifierForgetter(estimator\u001b[38;5;241m=\u001b[39mbase_model, learning_rate\u001b[38;5;241m=\u001b[39mlr, n_estimators\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m     14\u001b[0m forg\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m---> 15\u001b[0m _, y_compressed \u001b[38;5;241m=\u001b[39m \u001b[43mforg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_compressed))\n",
      "File \u001b[1;32mc:\\Users\\Antoine\\miniconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Antoine\\Desktop\\CIA\\BoostingProject\\Forgetters\\BaseForgetter.py:15\u001b[0m, in \u001b[0;36mBaseForgetter.transform\u001b[1;34m(self, X, compression_strategy, y)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, compression_strategy, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):     \n\u001b[1;32m---> 15\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mcompression_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_compression_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions_over_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m X[mask]\n",
      "File \u001b[1;32mc:\\Users\\Antoine\\Desktop\\CIA\\BoostingProject\\CompressionStrategies\\DropNForgets.py:27\u001b[0m, in \u001b[0;36mDropNForgetsClassification.get_compression_mask\u001b[1;34m(self, y_over_time, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m     new_forgotten_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbitwise_and(last_predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, new_predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     25\u001b[0m     forget_counts \u001b[38;5;241m=\u001b[39m forget_counts \u001b[38;5;241m+\u001b[39m new_forgotten_points\n\u001b[1;32m---> 27\u001b[0m     last_predictions \u001b[38;5;241m=\u001b[39m new_predictions\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremember:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforget_counts \u001b[38;5;241m=\u001b[39m forget_counts\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# List datasets with specific criteria (e.g., classification with >2 classes)\n",
    "datasets = openml.datasets.list_datasets(tag='OpenML100')\n",
    "filtered_datasets = [\n",
    "    ds for ds in datasets.values()\n",
    "    if ds['NumberOfClasses'] > 2 and ds['NumberOfInstances'] < 10000  # Optional size filter\n",
    "]\n",
    "\n",
    "# Display filtered dataset information\n",
    "df = pd.DataFrame(filtered_datasets)\n",
    "\n",
    "for dataset_id in df.iloc[:]['did']:\n",
    "    dataset = openml.datasets.get_dataset(int(dataset_id))\n",
    "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
    "    \n",
    "    # Convert y to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = pd.DataFrame(y)\n",
    "\n",
    "    plot_dataset_convergence(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
